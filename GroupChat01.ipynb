{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AutoGen/blob/main/GroupChat01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autogen dask[dataframe]"
      ],
      "metadata": {
        "id": "iP8G1At09aHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "82Ao7lzwrBvx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(api_key)"
      ],
      "metadata": {
        "id": "3Irtrciwqxfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile, os\n",
        "from autogen.coding import LocalCommandLineCodeExecutor"
      ],
      "metadata": {
        "id": "rXT5M0Vpha7l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dir = tempfile.TemporaryDirectory()\n",
        "executor = LocalCommandLineCodeExecutor(\n",
        "    timeout=1200,  # Timeout for each code execution in seconds.\n",
        "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
        ")\n",
        "\n",
        "gpt4_config = {\n",
        "    \"cache_seed\": False,  # change the cache_seed for different trials\n",
        "    \"temperature\": 0,\n",
        "    \"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}],\n",
        "    \"timeout\": 1200,\n",
        "}"
      ],
      "metadata": {
        "id": "rZo2T4O7gVCa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load the API key from the .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "#첫 대화를 실행하는 에이전트\n",
        "initializer = autogen.UserProxyAgent(\n",
        "    name=\"Init\",\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\"\n",
        ")\n",
        "\n",
        "# 첫 번째 코드 실행기 에이전트\n",
        "executor1 = autogen.UserProxyAgent(\n",
        "    name=\"Executor1\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config={\"executor\": executor},\n",
        ")\n",
        "\n",
        "# 두 번째 코드 실행기 에이전트\n",
        "executor2 = autogen.UserProxyAgent(\n",
        "    name=\"Executor2\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config={\"executor\": executor},\n",
        ")\n",
        "\n",
        "gpt4_config[\"config_list\"][0][\"api_key\"] = api_key\n",
        "\n",
        "monitor = autogen.AssistantAgent(\n",
        "    name=\"Monitor\",\n",
        "    llm_config=gpt4_config,\n",
        "    system_message=\"당신은 코드 실행을 감시하고 결과를 보고하는 모니터입니다. 각 실행기의 결과를 분석하고 요약하여 보고해주세요.\"\n",
        ")\n",
        "\n",
        "def state_transition(last_speaker, groupchat):\n",
        "    if last_speaker == initializer:\n",
        "        return executor1\n",
        "    elif last_speaker == executor1:\n",
        "        return executor2\n",
        "    elif last_speaker == executor2:\n",
        "        return monitor\n",
        "    elif last_speaker == monitor:\n",
        "        return None  # 모니터 이후에 대화 종료\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# 그룹 채팅 매니저 설정\n",
        "groupchat = autogen.GroupChat(agents=[initializer, executor1, executor2, monitor], messages=[], max_round=10, speaker_selection_method=state_transition)\n",
        "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt4_config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RaNfsmFr9mU",
        "outputId": "d21625a7-6b1f-4056-f3d6-35280e0544d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-14 22:47:01] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-14 22:47:01] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드 블록 정의\n",
        "code_block = \"\"\"\n",
        "print(f\"테스트\")\n",
        "\"\"\"\n",
        "# initializer가 채팅 시작\n",
        "initializer.initiate_chat(\n",
        "    manager,\n",
        "    message=f\"코드 실행 테스트를 시작합니다. Executor1과 Executor2가 순차적으로 다음 코드를 실행하고, Monitor가 결과를 분석할 것입니다. \\n코드실행기는 다음 코드를 실행하세요.:\\n```python\\n{code_block}\\n```\"\n",
        ")\n",
        "\n",
        "# Executor1에게 코드 실행 요청\n",
        "executor1.send(\n",
        "    message=f\"다음 코드를 실행하고 결과를 보고해주세요:\\n```python\\n{code_block}\\n```\",\n",
        "    recipient=manager\n",
        ")\n",
        "\n",
        "# Executor2에게 코드 실행 요청\n",
        "executor2.send(\n",
        "    message=f\"다음 코드를 실행하고 결과를 보고해주세요:\\n```python\\n{code_block}\\n```\",\n",
        "    recipient=manager\n",
        ")\n",
        "\n",
        "# Monitor에게 결과 분석 요청\n",
        "monitor.send(\n",
        "    message=\"Executor1과 Executor2의 코드 실행 결과를 분석하고 보고해주세요.\",\n",
        "    recipient=manager\n",
        ")"
      ],
      "metadata": {
        "id": "26S2qfzdifRm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}