{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AutoGen/blob/main/Reflection-NestedChat01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc3024e2",
      "metadata": {
        "id": "fc3024e2"
      },
      "source": [
        "# Lesson 3: Reflection and Blogpost Writing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b0cc42f",
      "metadata": {
        "id": "3b0cc42f"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/JSJeong-me/GPT-Agent/main/autogen/requirements.txt\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP974bhx5vU3",
        "outputId": "92850ae7-c9a5-4bd8-841b-ef3e3139dc01"
      },
      "id": "EP974bhx5vU3",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-14 23:39:33--  https://raw.githubusercontent.com/JSJeong-me/GPT-Agent/main/autogen/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 222 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "requirements.txt    100%[===================>]     222  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-14 23:39:34 (16.6 MB/s) - ‘requirements.txt’ saved [222/222]\n",
            "\n",
            "Collecting pyautogen==0.2.25 (from -r requirements.txt (line 6))\n",
            "  Downloading pyautogen-0.2.25-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting chess==1.10.0 (from -r requirements.txt (line 7))\n",
            "  Downloading chess-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.1.4)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.2.43)\n",
            "Collecting diskcache (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting flaml (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading FLAML-2.2.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting openai>=1.3 (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading openai-1.45.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.2.25->-r requirements.txt (line 6)) (2.9.1)\n",
            "Collecting python-dotenv (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.2.25->-r requirements.txt (line 6)) (2.4.0)\n",
            "Collecting tiktoken (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 10)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 10)) (2024.1)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (4.3.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (3.17.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance->-r requirements.txt (line 11)) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance->-r requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25->-r requirements.txt (line 6)) (2.23.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (2024.8.30)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen==0.2.25->-r requirements.txt (line 6)) (2024.5.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Downloading pyautogen-0.2.25-py3-none-any.whl (257 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.1/257.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chess-1.10.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.45.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.1/374.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.2/297.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, jiter, h11, flaml, diskcache, chess, tiktoken, httpcore, docker, httpx, openai, pyautogen\n",
            "Successfully installed chess-1.10.0 diskcache-5.6.3 docker-7.1.0 flaml-2.2.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.45.0 pyautogen-0.2.25 python-dotenv-1.0.1 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask[dataframe]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77-W_EMN5wCm",
        "outputId": "803e8d75-68fc-4512-b82e-f8db373397fe"
      },
      "id": "77-W_EMN5wCm",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2024.7.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.1)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.5.0)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.1.4)\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[dataframe])\n",
            "  Downloading dask_expr-1.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask_expr-1.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyarrow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (14.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.20.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.16.0)\n",
            "Downloading dask_expr-1.1.9-py3-none-any.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dask-expr\n",
            "Successfully installed dask-expr-1.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "mBEhzLqS51jU"
      },
      "id": "mBEhzLqS51jU",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "96d39be0-eaf3-456d-8613-ba21099ed36b",
      "metadata": {
        "height": 30,
        "id": "96d39be0-eaf3-456d-8613-ba21099ed36b"
      },
      "outputs": [],
      "source": [
        "llm_config={\"model\": \"gpt-3.5-turbo\",  \"api_key\": api_key } # os.environ.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0969e6bb",
      "metadata": {
        "id": "0969e6bb"
      },
      "source": [
        "## The task!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://raw.githubusercontent.com/JSJeong-me/GPT-Agent/main/autogen/utils.py"
      ],
      "metadata": {
        "id": "nk_3OXDx6EZX"
      },
      "id": "nk_3OXDx6EZX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e8074032-3690-4de9-ad08-ea8323cb441b",
      "metadata": {
        "height": 115,
        "id": "e8074032-3690-4de9-ad08-ea8323cb441b"
      },
      "outputs": [],
      "source": [
        "task = '''\n",
        "        딥러닝.AI에 대한 간결하면서도 매력적인 블로그 게시물을 작성하세요. 블로그 게시물은 100단어 이내여야 합니다.\n",
        "       '''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1987f023",
      "metadata": {
        "id": "1987f023"
      },
      "source": [
        "## Create a writer agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fe0f0a47-a9fe-43a0-b7b1-79922e4c4ac8",
      "metadata": {
        "height": 202,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe0f0a47-a9fe-43a0-b7b1-79922e4c4ac8",
        "outputId": "1fef84c6-5e1d-49ca-a793-f0010179999a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-14 23:40:12] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "import autogen\n",
        "\n",
        "writer = autogen.AssistantAgent(\n",
        "    name=\"Writer\",\n",
        "    system_message= \"당신은 작가입니다. 주어진 주제에 대해 흥미롭고 간결한 블로그 글(제목 포함)을 작성하세요. 피드백을 바탕으로 글을 다듬고 정제된 버전을 제공해야 합니다. 추가적인 설명 없이 최종 작업물만 제출하세요.\",\n",
        "    llm_config=llm_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7c7b4d8d-40f7-4a05-8958-25d20054de3a",
      "metadata": {
        "height": 49,
        "id": "7c7b4d8d-40f7-4a05-8958-25d20054de3a"
      },
      "outputs": [],
      "source": [
        "reply = writer.generate_reply(messages=[{\"content\": task, \"role\": \"user\"}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c501c97d-e338-4f36-a384-6ec45983cf77",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c501c97d-e338-4f36-a384-6ec45983cf77",
        "outputId": "5cf2578b-ae27-419a-e781-22049ba5daf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**제목: 미래를 여는 딥러닝, 인공지능의 진화**\n",
            "\n",
            "더 나은 미래를 향한 첫발인 딥러닝과 AI가 현재 삶에 어떠한 영향을 미치는지 알아보겠습니다. 딥러닝은 컴퓨터가 데이터를 스스로 학습하고 결정을 내리는 핵심 기술이며, AI는 인간 수준의 지능을 갖춘 시스템을 향한 진화의 과정입니다. 가상 비서부터 자율주행 자동차까지, 우리는 이미 AI 기술의 혜택을 많이 누리고 있습니다. 머지않은 미래에는 놀라운 혁신이 우리를 기다리고 있을 것입니다. 함께 미래를 여는 여정을 떠나봅시다.\n"
          ]
        }
      ],
      "source": [
        "print(reply)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49658114",
      "metadata": {
        "id": "49658114"
      },
      "source": [
        "## Adding reflection\n",
        "\n",
        "Create a critic agent to reflect on the work of the writer agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c7fcd1c7-51ec-4915-8e97-bac03565c4c7",
      "metadata": {
        "height": 168,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7fcd1c7-51ec-4915-8e97-bac03565c4c7",
        "outputId": "03dc3224-ad7d-44e5-e5e3-7f650a4f332f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-14 23:40:15] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "critic = autogen.AssistantAgent(\n",
        "    name=\"Critic\",\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"당신은 비평가입니다. 작가의 작품을 검토하고, 콘텐츠의 질을 향상시키기 위해 건설적인 피드백을 제공합니다.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "899d5fdb-6081-470b-b287-8cf8b8142d0d",
      "metadata": {
        "height": 115,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "899d5fdb-6081-470b-b287-8cf8b8142d0d",
        "outputId": "e1915e43-ab8f-4cdd-8cc1-0d0863438756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Critic (to Writer):\n",
            "\n",
            "\n",
            "        딥러닝.AI에 대한 간결하면서도 매력적인 블로그 게시물을 작성하세요. 블로그 게시물은 100단어 이내여야 합니다.\n",
            "       \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Writer (to Critic):\n",
            "\n",
            "**제목: 미래를 여는 딥러닝, 인공지능의 진화**\n",
            "\n",
            "더 나은 미래를 향한 첫발인 딥러닝과 AI가 현재 삶에 어떠한 영향을 미치는지 알아보겠습니다. 딥러닝은 컴퓨터가 데이터를 스스로 학습하고 결정을 내리는 핵심 기술이며, AI는 인간 수준의 지능을 갖춘 시스템을 향한 진화의 과정입니다. 가상 비서부터 자율주행 자동차까지, 우리는 이미 AI 기술의 혜택을 많이 누리고 있습니다. 머지않은 미래에는 놀라운 혁신이 우리를 기다리고 있을 것입니다. 함께 미래를 여는 여정을 떠나봅시다.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Critic (to Writer):\n",
            "\n",
            "작성하신 블로그 게시물은 매우 유익하고 흥미로운 내용을 담고 있습니다. 딥러닝과 AI에 대한 간결한 설명과 현재 우리 삶에 미치는 영향을 잘 풀어내셨습니다. 또한 미래에 대한 기대와 확신을 전달하는 부분도 매력적입니다. 추가적으로 실제 예시나 통계 데이터 등을 활용하여 내용을 더 소흘히 뒷받침한다면 독자들에게 더 큰 영감을 줄 수 있을 것입니다. 미래에 대한 호기심과 기대감을 자극하는 내용을 더욱 강조하면 좋을 것 같습니다. 함께 더 나은 미래를 여는 여정을 계속해서 이야기해 보세요.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Writer (to Critic):\n",
            "\n",
            "**제목: 딥러닝과 AI, 미래를 여는 혁명의 시작**\n",
            "\n",
            "딥러닝과 AI는 우리 삶에 혁명을 가져오고 있습니다. 예를 들어, 의료 분야에서는 AI를 활용한 질병 진닝시스템이 이미 사용되고 있어 인간의 몇 십 배 빠른 속도로 정확한 진단을 제공합니다. 또한, 자동화된 공장에서는 딥러닝 기술이 생산성과 효율성을 향상시키고 있습니다. 이러한 혁신은 우리가 상상조차 못했던 미래를 열어가고 있습니다. 더 나아가, 급변하는 세상에서 딥러닝과 AI는 우리에게 더 많은 가능성을 제공할 것입니다. 함께 이 놀라운 여정을 즐겨봅시다.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "res = critic.initiate_chat(\n",
        "    recipient=writer,\n",
        "    message=task,\n",
        "    max_turns=2,\n",
        "    summary_method=\"last_msg\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b76449",
      "metadata": {
        "id": "e7b76449"
      },
      "source": [
        "## Nested chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "401ecf92-63e9-40ff-aeed-1c404352e4ab",
      "metadata": {
        "height": 219,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "401ecf92-63e9-40ff-aeed-1c404352e4ab",
        "outputId": "b44c9351-fceb-4c16-c452-dad21fe5e32b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-14 23:40:22] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "SEO_reviewer = autogen.AssistantAgent(\n",
        "    name=\"SEO Reviewer\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"You are an SEO reviewer, known for \"\n",
        "        \"your ability to optimize content for search engines, \"\n",
        "        \"ensuring that it ranks well and attracts organic traffic. \"\n",
        "        \"Make sure your suggestion is concise (within 3 bullet points), \"\n",
        "        \"concrete and to the point. \"\n",
        "        \"Begin the review by stating your role.\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f85acb81-7ab9-4c84-b8bb-6fbae3dce848",
      "metadata": {
        "height": 202,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f85acb81-7ab9-4c84-b8bb-6fbae3dce848",
        "outputId": "fbffd47d-1a99-42f3-88bd-2b8c506002b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-14 23:40:22] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "legal_reviewer = autogen.AssistantAgent(\n",
        "    name=\"Legal Reviewer\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"You are a legal reviewer, known for \"\n",
        "        \"your ability to ensure that content is legally compliant \"\n",
        "        \"and free from any potential legal issues. \"\n",
        "        \"Make sure your suggestion is concise (within 3 bullet points), \"\n",
        "        \"concrete and to the point. \"\n",
        "        \"Begin the review by stating your role.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d46a177a-8088-4956-8d2b-3e916b8ca5e9",
      "metadata": {
        "height": 202,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d46a177a-8088-4956-8d2b-3e916b8ca5e9",
        "outputId": "54719404-7ab7-466f-8cb2-c9522f58ef16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-14 23:40:22] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "ethics_reviewer = autogen.AssistantAgent(\n",
        "    name=\"Ethics Reviewer\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"You are an ethics reviewer, known for \"\n",
        "        \"your ability to ensure that content is ethically sound \"\n",
        "        \"and free from any potential ethical issues. \"\n",
        "        \"Make sure your suggestion is concise (within 3 bullet points), \"\n",
        "        \"concrete and to the point. \"\n",
        "        \"Begin the review by stating your role. \",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a7b2ad6f-8ba6-436a-9459-14ffbe8a32d3",
      "metadata": {
        "height": 134,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7b2ad6f-8ba6-436a-9459-14ffbe8a32d3",
        "outputId": "d94ae88f-0b8f-4072-8eb7-a7d4d6375ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-14 23:40:23] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ],
      "source": [
        "meta_reviewer = autogen.AssistantAgent(\n",
        "    name=\"Meta Reviewer\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"You are a meta reviewer, you aggragate and review \"\n",
        "    \"the work of other reviewers and give a final suggestion on the content.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "913beca1",
      "metadata": {
        "id": "913beca1"
      },
      "source": [
        "## Orchestrate the nested chats to solve the task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a11a70c7-19ca-4e5a-ad3d-f2b481fb5915",
      "metadata": {
        "height": 559,
        "id": "a11a70c7-19ca-4e5a-ad3d-f2b481fb5915"
      },
      "outputs": [],
      "source": [
        "def reflection_message(recipient, messages, sender, config):\n",
        "    return f'''Review the following content.\n",
        "            \\n\\n {recipient.chat_messages_for_summary(sender)[-1]['content']}'''\n",
        "\n",
        "review_chats = [\n",
        "    {\n",
        "     \"recipient\": SEO_reviewer,\n",
        "     \"message\": reflection_message,\n",
        "     \"summary_method\": \"reflection_with_llm\",\n",
        "     \"summary_args\": {\"summary_prompt\" :\n",
        "        \"Return review into as JSON object only:\"\n",
        "        \"{'Reviewer': '', 'Review': ''}. Here Reviewer should be your role\",},\n",
        "     \"max_turns\": 1},\n",
        "    {\n",
        "    \"recipient\": legal_reviewer, \"message\": reflection_message,\n",
        "     \"summary_method\": \"reflection_with_llm\",\n",
        "     \"summary_args\": {\"summary_prompt\" :\n",
        "        \"Return review into as JSON object only:\"\n",
        "        \"{'Reviewer': '', 'Review': ''}.\",},\n",
        "     \"max_turns\": 1},\n",
        "    {\"recipient\": ethics_reviewer, \"message\": reflection_message,\n",
        "     \"summary_method\": \"reflection_with_llm\",\n",
        "     \"summary_args\": {\"summary_prompt\" :\n",
        "        \"Return review into as JSON object only:\"\n",
        "        \"{'reviewer': '', 'review': ''}\",},\n",
        "     \"max_turns\": 1},\n",
        "     {\"recipient\": meta_reviewer,\n",
        "      \"message\": \"Aggregrate feedback from all reviewers and give final suggestions on the writing.\",\n",
        "     \"max_turns\": 1},\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b3a40b66-5061-460d-ad9d-c0dbcfbba2e9",
      "metadata": {
        "height": 81,
        "id": "b3a40b66-5061-460d-ad9d-c0dbcfbba2e9"
      },
      "outputs": [],
      "source": [
        "critic.register_nested_chats(\n",
        "    review_chats,\n",
        "    trigger=writer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43b8797d",
      "metadata": {
        "id": "43b8797d"
      },
      "source": [
        "**Note**: You might get a slightly different response than what's shown in the video. Feel free to try different task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3b8dcac3-1e72-43b7-9d5a-1be740f6efd5",
      "metadata": {
        "height": 115,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b8dcac3-1e72-43b7-9d5a-1be740f6efd5",
        "outputId": "042ca25b-eb46-4fc1-ecc5-0125d15a7aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Critic (to Writer):\n",
            "\n",
            "\n",
            "        딥러닝.AI에 대한 간결하면서도 매력적인 블로그 게시물을 작성하세요. 블로그 게시물은 100단어 이내여야 합니다.\n",
            "       \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Writer (to Critic):\n",
            "\n",
            "**제목: 미래를 여는 딥러닝, 인공지능의 진화**\n",
            "\n",
            "더 나은 미래를 향한 첫발인 딥러닝과 AI가 현재 삶에 어떠한 영향을 미치는지 알아보겠습니다. 딥러닝은 컴퓨터가 데이터를 스스로 학습하고 결정을 내리는 핵심 기술이며, AI는 인간 수준의 지능을 갖춘 시스템을 향한 진화의 과정입니다. 가상 비서부터 자율주행 자동차까지, 우리는 이미 AI 기술의 혜택을 많이 누리고 있습니다. 머지않은 미래에는 놀라운 혁신이 우리를 기다리고 있을 것입니다. 함께 미래를 여는 여정을 떠나봅시다.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Critic (to SEO Reviewer):\n",
            "\n",
            "Review the following content. \n",
            "            \n",
            "\n",
            " **제목: 미래를 여는 딥러닝, 인공지능의 진화**\n",
            "\n",
            "더 나은 미래를 향한 첫발인 딥러닝과 AI가 현재 삶에 어떠한 영향을 미치는지 알아보겠습니다. 딥러닝은 컴퓨터가 데이터를 스스로 학습하고 결정을 내리는 핵심 기술이며, AI는 인간 수준의 지능을 갖춘 시스템을 향한 진화의 과정입니다. 가상 비서부터 자율주행 자동차까지, 우리는 이미 AI 기술의 혜택을 많이 누리고 있습니다. 머지않은 미래에는 놀라운 혁신이 우리를 기다리고 있을 것입니다. 함께 미래를 여는 여정을 떠나봅시다.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "SEO Reviewer (to Critic):\n",
            "\n",
            "As an SEO reviewer:\n",
            "\n",
            "- Consider incorporating more specific keywords related to deep learning and artificial intelligence throughout the content to improve search engine visibility.\n",
            "- Include subheadings that highlight key points such as applications of AI in daily life and future innovations for better organization and SEO optimization.\n",
            "- Add relevant internal and external links to authoritative sources that can enhance the credibility and SEO performance of the content.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Critic (to Legal Reviewer):\n",
            "\n",
            "Review the following content. \n",
            "            \n",
            "\n",
            " **제목: 미래를 여는 딥러닝, 인공지능의 진화**\n",
            "\n",
            "더 나은 미래를 향한 첫발인 딥러닝과 AI가 현재 삶에 어떠한 영향을 미치는지 알아보겠습니다. 딥러닝은 컴퓨터가 데이터를 스스로 학습하고 결정을 내리는 핵심 기술이며, AI는 인간 수준의 지능을 갖춘 시스템을 향한 진화의 과정입니다. 가상 비서부터 자율주행 자동차까지, 우리는 이미 AI 기술의 혜택을 많이 누리고 있습니다. 머지않은 미래에는 놀라운 혁신이 우리를 기다리고 있을 것입니다. 함께 미래를 여는 여정을 떠나봅시다.\n",
            "Context: \n",
            "{'Reviewer': 'SEO reviewer', 'Review': '- Consider incorporating more specific keywords related to deep learning and artificial intelligence throughout the content to improve search engine visibility.\\n- Include subheadings that highlight key points such as applications of AI in daily life and future innovations for better organization and SEO optimization.\\n- Add relevant internal and external links to authoritative sources that can enhance the credibility and SEO performance of the content.'}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Legal Reviewer (to Critic):\n",
            "\n",
            "**Role: Legal Reviewer**\n",
            "\n",
            "- Ensure that the content does not make any overly speculative claims about the future benefits or advancements of deep learning and AI to avoid potential false advertising or misrepresentation issues.\n",
            "- Confirm that any references made to specific AI technologies or companies are accurate and not misleading to prevent potential defamation or intellectual property infringement concerns.\n",
            "- Verify that any statements regarding the impact of AI on daily life are backed by reliable sources to avoid potential misinformation or deceptive advertising claims.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Critic (to Ethics Reviewer):\n",
            "\n",
            "Review the following content. \n",
            "            \n",
            "\n",
            " **제목: 미래를 여는 딥러닝, 인공지능의 진화**\n",
            "\n",
            "더 나은 미래를 향한 첫발인 딥러닝과 AI가 현재 삶에 어떠한 영향을 미치는지 알아보겠습니다. 딥러닝은 컴퓨터가 데이터를 스스로 학습하고 결정을 내리는 핵심 기술이며, AI는 인간 수준의 지능을 갖춘 시스템을 향한 진화의 과정입니다. 가상 비서부터 자율주행 자동차까지, 우리는 이미 AI 기술의 혜택을 많이 누리고 있습니다. 머지않은 미래에는 놀라운 혁신이 우리를 기다리고 있을 것입니다. 함께 미래를 여는 여정을 떠나봅시다.\n",
            "Context: \n",
            "{'Reviewer': 'SEO reviewer', 'Review': '- Consider incorporating more specific keywords related to deep learning and artificial intelligence throughout the content to improve search engine visibility.\\n- Include subheadings that highlight key points such as applications of AI in daily life and future innovations for better organization and SEO optimization.\\n- Add relevant internal and external links to authoritative sources that can enhance the credibility and SEO performance of the content.'}\n",
            "{'Reviewer': 'Legal Reviewer', 'Review': '- Ensure that the content does not make any overly speculative claims about the future benefits or advancements of deep learning and AI to avoid potential false advertising or misrepresentation issues.\\n- Confirm that any references made to specific AI technologies or companies are accurate and not misleading to prevent potential defamation or intellectual property infringement concerns.\\n- Verify that any statements regarding the impact of AI on daily life are backed by reliable sources to avoid potential misinformation or deceptive advertising claims.'}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Ethics Reviewer (to Critic):\n",
            "\n",
            "**Ethics Reviewer**\n",
            "\n",
            "- Ensure that the content does not exaggerate the capabilities or potential of AI and deep learning, avoiding false advertising or misleading claims.\n",
            "- Verify that any references to specific AI technologies or companies are accurate to prevent defamation or intellectual property infringement issues.\n",
            "- Check for reliable and credible sources to support statements about the impact of AI on daily life, avoiding potential misinformation or deceptive advertising claims.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Critic (to Meta Reviewer):\n",
            "\n",
            "Aggregrate feedback from all reviewers and give final suggestions on the writing.\n",
            "Context: \n",
            "{'Reviewer': 'SEO reviewer', 'Review': '- Consider incorporating more specific keywords related to deep learning and artificial intelligence throughout the content to improve search engine visibility.\\n- Include subheadings that highlight key points such as applications of AI in daily life and future innovations for better organization and SEO optimization.\\n- Add relevant internal and external links to authoritative sources that can enhance the credibility and SEO performance of the content.'}\n",
            "{'Reviewer': 'Legal Reviewer', 'Review': '- Ensure that the content does not make any overly speculative claims about the future benefits or advancements of deep learning and AI to avoid potential false advertising or misrepresentation issues.\\n- Confirm that any references made to specific AI technologies or companies are accurate and not misleading to prevent potential defamation or intellectual property infringement concerns.\\n- Verify that any statements regarding the impact of AI on daily life are backed by reliable sources to avoid potential misinformation or deceptive advertising claims.'}\n",
            "{'reviewer': 'Ethics Reviewer', 'review': '- Ensure that the content does not exaggerate the capabilities or potential of AI and deep learning, avoiding false advertising or misleading claims.\\n- Verify that any references to specific AI technologies or companies are accurate to prevent defamation or intellectual property infringement issues.\\n- Check for reliable and credible sources to support statements about the impact of AI on daily life, avoiding potential misinformation or deceptive advertising claims.'}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Meta Reviewer (to Critic):\n",
            "\n",
            "Aggregated Feedback:\n",
            "\n",
            "1. SEO Reviewer:\n",
            "- Incorporate more specific keywords related to deep learning and artificial intelligence for better search engine visibility\n",
            "- Include subheadings highlighting key points for better organization and SEO optimization\n",
            "- Add relevant internal and external links to enhance credibility and SEO performance\n",
            "\n",
            "2. Legal Reviewer:\n",
            "- Avoid making overly speculative claims about future benefits or advancements of AI to prevent false advertising issues\n",
            "- Ensure accuracy when referencing specific AI technologies or companies to avoid defamation or intellectual property infringement\n",
            "- Verify that statements about the impact of AI on daily life are supported by reliable sources to prevent misinformation or deceptive advertising claims\n",
            "\n",
            "3. Ethics Reviewer:\n",
            "- Avoid exaggerating the capabilities or potential of AI and deep learning to prevent false advertising or misleading claims\n",
            "- Ensure accuracy in references to specific AI technologies or companies to prevent defamation or intellectual property infringement\n",
            "- Use reliable and credible sources to support statements about the impact of AI on daily life to avoid misinformation or deceptive advertising claims\n",
            "\n",
            "Final Suggestions:\n",
            "Based on the feedback from the reviewers, it is important to:\n",
            "- Incorporate specific keywords related to AI and deep learning for SEO purposes\n",
            "- Organize the content with subheadings highlighting key points\n",
            "- Add internal and external links to authoritative sources for credibility\n",
            "- Avoid making speculative or exaggerated claims about AI advancements\n",
            "- Ensure accuracy in referencing AI technologies or companies\n",
            "- Support statements about AI's impact with reliable sources\n",
            "\n",
            "By addressing these suggestions, the content can maintain accuracy, credibility, and compliance with SEO best practices, legal considerations, and ethical standards in discussing deep learning and artificial intelligence.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Critic (to Writer):\n",
            "\n",
            "Aggregated Feedback:\n",
            "\n",
            "1. SEO Reviewer:\n",
            "- Incorporate more specific keywords related to deep learning and artificial intelligence for better search engine visibility\n",
            "- Include subheadings highlighting key points for better organization and SEO optimization\n",
            "- Add relevant internal and external links to enhance credibility and SEO performance\n",
            "\n",
            "2. Legal Reviewer:\n",
            "- Avoid making overly speculative claims about future benefits or advancements of AI to prevent false advertising issues\n",
            "- Ensure accuracy when referencing specific AI technologies or companies to avoid defamation or intellectual property infringement\n",
            "- Verify that statements about the impact of AI on daily life are supported by reliable sources to prevent misinformation or deceptive advertising claims\n",
            "\n",
            "3. Ethics Reviewer:\n",
            "- Avoid exaggerating the capabilities or potential of AI and deep learning to prevent false advertising or misleading claims\n",
            "- Ensure accuracy in references to specific AI technologies or companies to prevent defamation or intellectual property infringement\n",
            "- Use reliable and credible sources to support statements about the impact of AI on daily life to avoid misinformation or deceptive advertising claims\n",
            "\n",
            "Final Suggestions:\n",
            "Based on the feedback from the reviewers, it is important to:\n",
            "- Incorporate specific keywords related to AI and deep learning for SEO purposes\n",
            "- Organize the content with subheadings highlighting key points\n",
            "- Add internal and external links to authoritative sources for credibility\n",
            "- Avoid making speculative or exaggerated claims about AI advancements\n",
            "- Ensure accuracy in referencing AI technologies or companies\n",
            "- Support statements about AI's impact with reliable sources\n",
            "\n",
            "By addressing these suggestions, the content can maintain accuracy, credibility, and compliance with SEO best practices, legal considerations, and ethical standards in discussing deep learning and artificial intelligence.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Writer (to Critic):\n",
            "\n",
            "**Title: Navigating the Evolution of AI and Deep Learning**\n",
            "\n",
            "Embark on a journey to explore the profound influence of deep learning and AI on our daily lives. Deep learning empowers computers to learn and make decisions autonomously, while AI represents the evolution towards human-level intelligence. From virtual assistants to self-driving cars, we are already reaping the benefits of AI technology. The future holds even more remarkable innovations. Let's navigate this path together and discover the endless possibilities. Embrace the transformative power of AI and deep learning as we step into a future where technology shapes the world around us.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "res = critic.initiate_chat(\n",
        "    recipient=writer,\n",
        "    message=task,\n",
        "    max_turns=2,\n",
        "    summary_method=\"last_msg\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5c833b0",
      "metadata": {
        "id": "c5c833b0"
      },
      "source": [
        "## Get the summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "68ef82ed-f102-4964-b7be-60e2f258a39b",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68ef82ed-f102-4964-b7be-60e2f258a39b",
        "outputId": "3e7d8b38-a3e1-4aba-a0ac-a6cb9cbd0bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Title: Navigating the Evolution of AI and Deep Learning**\n",
            "\n",
            "Embark on a journey to explore the profound influence of deep learning and AI on our daily lives. Deep learning empowers computers to learn and make decisions autonomously, while AI represents the evolution towards human-level intelligence. From virtual assistants to self-driving cars, we are already reaping the benefits of AI technology. The future holds even more remarkable innovations. Let's navigate this path together and discover the endless possibilities. Embrace the transformative power of AI and deep learning as we step into a future where technology shapes the world around us.\n"
          ]
        }
      ],
      "source": [
        "print(res.summary)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}