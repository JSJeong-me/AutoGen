{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AutoGen/blob/main/L1_Multi-Agent_Conversation_and_Stand-up_Comedy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a81456dd",
      "metadata": {
        "id": "a81456dd"
      },
      "source": [
        "# Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4693467e",
      "metadata": {
        "id": "4693467e"
      },
      "source": [
        "Welcome to Lesson 1.\n",
        "\n",
        "To access the `requirements.txt` file and the`utils` modules, please go to the `File` menu and select`Open...`.\n",
        "\n",
        "I hope you enjoy this course!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742cf649",
      "metadata": {
        "id": "742cf649"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "eJDSIg0VZCoD",
        "outputId": "69ccd1cc-1b5a-478d-cd9a-5a028a35c29e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eJDSIg0VZCoD",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen==0.2.25 (from -r requirements.txt (line 6))\n",
            "  Downloading pyautogen-0.2.25-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.1/257.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chess==1.10.0 (from -r requirements.txt (line 7))\n",
            "  Downloading chess-1.10.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.0.3)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.2.40)\n",
            "Collecting diskcache (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flaml (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading FLAML-2.1.2-py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai>=1.3 (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading openai-1.35.1-py3-none-any.whl (326 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.8/326.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.2.25->-r requirements.txt (line 6)) (2.7.3)\n",
            "Collecting python-dotenv (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.2.25->-r requirements.txt (line 6)) (2.4.0)\n",
            "Collecting tiktoken (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 10)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 10)) (2024.1)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (4.2.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (3.17.5)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance->-r requirements.txt (line 11)) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance->-r requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25->-r requirements.txt (line 6)) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (2024.6.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen==0.2.25->-r requirements.txt (line 6)) (2024.5.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.2.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, h11, flaml, diskcache, chess, tiktoken, httpcore, docker, httpx, openai, pyautogen\n",
            "Successfully installed chess-1.10.0 diskcache-5.6.3 docker-7.1.0 flaml-2.1.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.1 pyautogen-0.2.25 python-dotenv-1.0.1 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your utilities or helper functions to this file.\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# these expect to find a .env file at the directory above the lesson.                                                                                                                     # the format for that file is (without the comment)                                                                                                                                       #API_KEYNAME=AStringThatIsTheLongAPIKeyFromSomeService\n",
        "def load_env():\n",
        "    _ = load_dotenv(find_dotenv())\n",
        "\n",
        "def get_openai_api_key():\n",
        "    load_env()\n",
        "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    return openai_api_key\n"
      ],
      "metadata": {
        "id": "aTMQRqYWZNy6"
      },
      "id": "aTMQRqYWZNy6",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "04d006c1-22fa-40ea-b3e0-d543142e0788",
      "metadata": {
        "height": 64,
        "id": "04d006c1-22fa-40ea-b3e0-d543142e0788"
      },
      "outputs": [],
      "source": [
        "# from utils import get_openai_api_key\n",
        "OPENAI_API_KEY = get_openai_api_key()\n",
        "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "116a1c4d",
      "metadata": {
        "id": "116a1c4d"
      },
      "source": [
        "## Define an AutoGen agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5",
      "metadata": {
        "height": 132,
        "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5"
      },
      "outputs": [],
      "source": [
        "from autogen import ConversableAgent\n",
        "\n",
        "agent = ConversableAgent(\n",
        "    name=\"chatbot\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
      "metadata": {
        "height": 81,
        "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
        "outputId": "615bf8b8-c4b9-4e70-f930-45a4154ab174",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here you go: Why don't scientists trust atoms? Because they make up everything!\n"
          ]
        }
      ],
      "source": [
        "reply = agent.generate_reply(\n",
        "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
        ")\n",
        "print(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
      "metadata": {
        "height": 81,
        "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
        "outputId": "5d2301fc-6167-4220-e4d4-b763d739834b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of course! Just let me know which joke you'd like to hear again.\n"
          ]
        }
      ],
      "source": [
        "reply = agent.generate_reply(\n",
        "    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",
        ")\n",
        "print(reply)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c98a301",
      "metadata": {
        "id": "8c98a301"
      },
      "source": [
        "## Conversation\n",
        "\n",
        "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c",
      "metadata": {
        "height": 285,
        "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c"
      },
      "outputs": [],
      "source": [
        "Cat = ConversableAgent(\n",
        "    name=\"cat\",\n",
        "    system_message=\n",
        "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "Dog = ConversableAgent(\n",
        "    name=\"dog\",\n",
        "    system_message=\n",
        "    \"Your name is Joe and you are a stand-up comedian. \"\n",
        "    \"Start the next joke from the punchline of the previous joke.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43f71a61",
      "metadata": {
        "id": "43f71a61"
      },
      "source": [
        "**Note**: You might get a slightly different response (set of jokes) than what is shown in the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
      "metadata": {
        "height": 98,
        "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
        "outputId": "e3f71253-83e2-4483-85c6-50da4fa6d680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog (to cat):\n",
            "\n",
            "I'm Joe. Cat, let's keep the jokes rolling.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cat (to dog):\n",
            "\n",
            "All right, Joe! So, you know you're getting old when you start to appreciate the intricacies of the snooze button more than a Friday night out. But hey, at least hitting snooze counts as exercise, right?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "dog (to cat):\n",
            "\n",
            "Haha, that's right! Hitting snooze is my cardio for the day. It's like my own personal time-travel workout.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cat (to dog):\n",
            "\n",
            "Absolutely, Joe! It's the only workout where you can travel to the future in 9-minute intervals. I'm pretty sure hitting snooze burns more calories than hitting the gym... at least, that's what I tell myself every morning!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "chat_result = Dog.initiate_chat(\n",
        "    recipient=Cat,\n",
        "    message=\"I'm Dog. Cat, let's keep the jokes rolling.\",\n",
        "    max_turns=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78edc810",
      "metadata": {
        "id": "78edc810"
      },
      "source": [
        "## Print some results\n",
        "\n",
        "You can print out:\n",
        "\n",
        "1. Chat history\n",
        "2. Cost\n",
        "3. Summary of the conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
      "metadata": {
        "height": 64,
        "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
        "outputId": "bb93d252-b2ad-47d0-afd1-577a1eb0c439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'content': \"I'm Joe. Cat, let's keep the jokes rolling.\",\n",
            "  'role': 'assistant'},\n",
            " {'content': \"All right, Joe! So, you know you're getting old when you start \"\n",
            "             'to appreciate the intricacies of the snooze button more than a '\n",
            "             'Friday night out. But hey, at least hitting snooze counts as '\n",
            "             'exercise, right?',\n",
            "  'role': 'user'},\n",
            " {'content': \"Haha, that's right! Hitting snooze is my cardio for the day. \"\n",
            "             \"It's like my own personal time-travel workout.\",\n",
            "  'role': 'assistant'},\n",
            " {'content': \"Absolutely, Joe! It's the only workout where you can travel to \"\n",
            "             \"the future in 9-minute intervals. I'm pretty sure hitting snooze \"\n",
            "             \"burns more calories than hitting the gym... at least, that's \"\n",
            "             'what I tell myself every morning!',\n",
            "  'role': 'user'}]\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(chat_result.chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
      "metadata": {
        "height": 30,
        "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
        "outputId": "38dfb4c1-8543-4876-c51c-022ad32b3281",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 125,\n",
            "                                                             'cost': 0.0003155,\n",
            "                                                             'prompt_tokens': 256,\n",
            "                                                             'total_tokens': 381},\n",
            "                                      'total_cost': 0.0003155},\n",
            " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 125,\n",
            "                                                             'cost': 0.0003155,\n",
            "                                                             'prompt_tokens': 256,\n",
            "                                                             'total_tokens': 381},\n",
            "                                      'total_cost': 0.0003155}}\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(chat_result.cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
      "metadata": {
        "height": 30,
        "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
        "outputId": "0eec7325-a990-4984-dea7-cf22f95b8ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"Absolutely, Joe! It's the only workout where you can travel to the future in \"\n",
            " \"9-minute intervals. I'm pretty sure hitting snooze burns more calories than \"\n",
            " \"hitting the gym... at least, that's what I tell myself every morning!\")\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(chat_result.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba8c6cf8",
      "metadata": {
        "id": "ba8c6cf8"
      },
      "source": [
        "## Get a better summary of the conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
      "metadata": {
        "height": 132,
        "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
        "outputId": "97182ca4-4aa0-439a-f2f3-0ca9bab3663f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog (to cat):\n",
            "\n",
            "I'm Dog. Cat, let's keep the jokes rolling.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cat (to dog):\n",
            "\n",
            "Hey Dog, I'm Cathy not Cat! But sure, let's keep the jokes coming. So, why did the dog sit in the shade?\n",
            "\n",
            "Because he didn't want to be a hot dog!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "dog (to cat):\n",
            "\n",
            "Well, Cathy, it sounds like that dog had some good \"paws\" on his shoulders!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cat (to dog):\n",
            "\n",
            "Haha, well, Dog, it sounds like you've got a great sense of humor! Maybe I should paws and let you take over the stand-up stage!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "chat_result = Dog.initiate_chat(\n",
        "    Cat,\n",
        "    message=\"I'm Dog. Cat, let's keep the jokes rolling.\",\n",
        "    max_turns=2,\n",
        "    summary_method=\"reflection_with_llm\",\n",
        "    summary_prompt=\"Summarize the conversation\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
      "metadata": {
        "height": 30,
        "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
        "outputId": "9d1a90a0-0049-47b3-ad52-8ffc0ca2dd07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Dog and Cathy exchanged jokes and puns with each other, showcasing their '\n",
            " 'sense of humor and playfulness.')\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(chat_result.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "300525bd",
      "metadata": {
        "id": "300525bd"
      },
      "source": [
        "## Chat Termination\n",
        "\n",
        "Chat can be terminated using a termination conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70",
      "metadata": {
        "height": 336,
        "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70"
      },
      "outputs": [],
      "source": [
        "cathy = ConversableAgent(\n",
        "    name=\"cathy\",\n",
        "    system_message=\n",
        "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
        "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
        ")\n",
        "\n",
        "joe = ConversableAgent(\n",
        "    name=\"joe\",\n",
        "    system_message=\n",
        "    \"Your name is Joe and you are a stand-up comedian. \"\n",
        "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
      "metadata": {
        "height": 81,
        "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
        "outputId": "59d9b8a9-0ca3-48a5-bcf4-cff42b27be7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joe (to cathy):\n",
            "\n",
            "I'm Joe. Cathy, let's keep the jokes rolling.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Hey Joe, sounds like a plan! Why did the math book look sad? Because it had too many problems.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "Haha, good one! Here's a math joke for you: Why was the equal sign so humble? Because he knew he wasn't less than or greater than anyone else.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Haha, I love a good math joke! Here's one for you: Why did the student do multiplication problems on the floor? The teacher told him not to use tables!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "Haha, classic! Alright, Cathy, you've got some good jokes. But my time is up now. Take care and keep those jokes coming!\n",
            "\n",
            "I gotta go.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "chat_result = joe.initiate_chat(\n",
        "    recipient=cathy,\n",
        "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
      "metadata": {
        "height": 30,
        "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
        "outputId": "a1504800-3f61-4416-ca24-cc525e9d769f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cathy (to joe):\n",
            "\n",
            "What's last joke we talked about?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "We were talking about math jokes! \"Why did the student do multiplication problems on the floor? The teacher told him not to use tables!\"\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "I'm a bit confused. Do you want to continue the conversation?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "I appreciate your interest, but I really do have to go now. Have a great day!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Got it! Have a great day and thanks for the laughs, Joe!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "You're welcome! Take care, Cathy!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "You too, Joe! Goodbye!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}